
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Machine Reading - AI and ML Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#machine-reading" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="AI and ML Notes" class="md-header__button md-logo" aria-label="AI and ML Notes" data-md-component="logo">
      
  <img src="../../assets/images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI and ML Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Machine Reading
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="AI and ML Notes" class="md-nav__button md-logo" aria-label="AI and ML Notes" data-md-component="logo">
      
  <img src="../../assets/images/logo.png" alt="logo">

    </a>
    AI and ML Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Patterns
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Patterns
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../patterns/stats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability & Statistics
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Machine Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml/bayes_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bayesian Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml/decision_trees/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decision Trees
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml/instance_based/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Instance Based Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml/nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural Nets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ml/svm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SVM
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    NLP
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            NLP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributional_semantics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributional Semantics
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Deep Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Deep Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    AI for Robotics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            AI for Robotics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../robotics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rl/game_theory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Game Theory
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#distant-supervision" class="md-nav__link">
    <span class="md-ellipsis">
      Distant Supervision
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="machine-reading">Machine Reading<a class="headerlink" href="#machine-reading" title="Permanent link">&para;</a></h1>
<p>Open information extraction: Extract structured knowledge from unstructured texted without knowing what the entities or relations are in advance. </p>
<p>This is unsupervised.</p>
<h2 id="distant-supervision">Distant Supervision<a class="headerlink" href="#distant-supervision" title="Permanent link">&para;</a></h2>
<p>We can get away from knowing fixed relationships. 
Instead of manually labeling from an existing knowledge base.</p>
<p>Positive Example: Every entity is related to another entity in a sentence. Jack loved his sister, Jill, very much. Jack and Jill are the entities connected by the relation, love. </p>
<p>Negative Example: No relation between entities. Jack and Jill went up the hill.</p>
<p>Open Info Extraction requires learning a way to recognize relations without labeling. The <strong>syntax</strong> of sentences provide clues about relations.</p>
<p>Semantics arise from syntax. "Jane loves science." We get the meaning because we understand Jane is entity, science is a concept, and love is their positive affinity relationship.</p>
<p>Part of Speech (POS) tagging.
Assign a POS tag to each word in a sentence.
Dynamic  Bayesian Network:
Everything in the top row (tags) are latent properties of the document: they don't really exist.
If tag is VRB we tend to see certain words we recognize as verbs, so the relationship is an 'emission.' P(word|tag). If a certain tag is present then it emits certain words with greater probability. 
It's a dynamic bayesian network because we have this tag1 &gt; tag2 relationship, sequentially. We tend to see certain things follow other tags. P(tag2|tag1)
Then we search for a set of tags that maximized the joint probability 
1. Time proceeding through network
tag1 &gt;  tag2 &gt;  tag3 
v       v       v
word1   word2   word3</p>
<p>Dynamic Programming:
We have words, not tags.
Compute most likely explanation MLE: What sequence of latent values would most likely emit the observed sequence of words. Use the trick of dynamic programming, assume that choosing most likely tag for each time slice results in the most likely explanation for the entire sequence.</p>
<p>Dependency Parsing
Words have relationships to each other
Graph-structured syntactic analysis of sentence that helps us find these relationships.
a. root is a verb
b arc are dependencies with types, telling us what is related and how.
c. shift-reduce parsing
1 build a dependency graph from the bottom up
2. Buffer: data structure: Processes a sentence word by word from a buffer
3. Stack: data structure: put words that we don't know what to do with in the stack.
4. Operations</p>
<p>But how do we know which operation (shift, left, or right?): Learn a classifier: supervised learning. 
Given: a stack, a buffer, and POS tags
Output: shift, left, right and maybe dependency type
Build the dataset:
1. distant supervision
2. annotate lots of sentences with dependency graphs/parses
manual process (people do it)
Run stack-reduced operation forward and backwards using different operations until it matches the annotations we put in.
This means backtracking when necessary to find the known graph
It predicts the operations we have to do to get the answers according humans
We end up with:
1 X: partial parses of sentences (buffer, stack, POS tags), different stages at each moment: Input to classifier.
2. Y: Best shift-reduce operations: labels for the classifier.</p>
<hr />
<p>Dependency Parsing
Words have relationships to each other
Graph-structured syntactic analysis of sentence that helps us find these relationships.
a. root is a verb
b arc are dependencies with types, telling us what is related and how.
c. shift-reduce parsing
1 build a dependency graph from the bottom up
2. Buffer: data structure: Processes a sentence word by word from a buffer
3. Stack: data structure: put words that we don't know what to do with in the stack.
4. Operations</p>
<p>But how do we know which operation (shift, left, or right?): Learn a classifier: supervised learning. 
Given: a stack, a buffer, and POS tags
Output: shift, left, right and maybe dependency type
Build the dataset:
1. distant supervision
2. annotate lots of sentences with dependency graphs/parses
manual process (people do it)
Run stack-reduced operation forward and backwards using different operations until it matches the annotations we put in.
This means backtracking when necessary to find the known graph
It predicts the operations we have to do to get the answers according humans
We end up with:
1 X: partial parses of sentences (buffer, stack, POS tags), different stages at each moment: Input to classifier.
2. Y: Best shift-reduce operations: labels for the classifier.</p>
<p>__</p>
<p>Dependency Parsing and Distant Supervision</p>
<p>Goal: </p>
<p>Analyze the grammatical structure of a sentence by building a dependency graph: a tree where</p>
<p>The root is usually a verb</p>
<p>Arcs are labeled with dependency types (e.g., subject, object) showing how words relate.</p>
<p>How do we build the dependency graph:</p>
<p>We use a shift-reduce parser, which processes the sentence bottom-up using:</p>
<p>A buffer: words we still need to process</p>
<p>A stack: words we've seen but haven't fully connected yet</p>
<p>Operations (shift, left-arc, right-arc): actions that modify the stack and buffer and build the graph</p>
<p>The problem: How we we know which operation to perform at each step?</p>
<p>Solution:
Train a classifier using supervised learning.</p>
<p>Building the Training Dataset: Distant Supervision
Since we need training examples of (stack, buffer, POS tags) mapped to best action, we simulate the parsing process using sentences already annotated with correct dependency trees (i.e., ground truth graphs).</p>
<p>Steps:</p>
<p>Manually annotated sentences:
Humans create gold-standard dependency parses for lots of sentences. These are the raw material for the training data, but not the final form of the training example the classifier sees directly</p>
<p>Replay parsing (shift-reduce simulation):
We simulate the parsing process forward, trying operations (shift, left-arc, right-arc).</p>
<p>Backtracking if necessary:
If a wrong operation is chosen, we backtrack and adjust to make sure the sequence of operations leads exactly to the human-annotated tree.</p>
<h1 id="create-training-examples">Create training examples:<a class="headerlink" href="#create-training-examples" title="Permanent link">&para;</a></h1>
<p>X (input): Current parser state (stack, buffer, POS tags at that moment)</p>
<p>Y (label): The correct next action (shift, left-arc, right-arc, with possibly a dependency label)</p>
<h1 id="why-is-this-called-distant-supervision">Why is this called "distant supervision"?<a class="headerlink" href="#why-is-this-called-distant-supervision" title="Permanent link">&para;</a></h1>
<p>We aren't labeling operations directly (no one manually labeled "shift here", "left-arc here").</p>
<p>Instead, we use the distant information (full annotated trees) and infer the correct operations needed to build them.</p>
<p>Supervision is based on final desired output, not step-by-step annotations.</p>
<p>In short:
We use final human-labeled parses to generate supervision over many intermediate parsing states.</p>
<p>Given gold parse:
"She eats apples" → "eats" is root, "She" is subject of "eats", "apples" is object of "eats."</p>
<p>The simulation will do (each of the following three is a training example):</p>
<p>Stack: [], Buffer: [She, eats, apples] → Action: shift</p>
<p>Stack: [She], Buffer: [eats, apples] → Action: shift</p>
<p>Stack: [She, eats], Buffer: [apples] → Action: left-arc (nsubj)</p>
<p>and so on...</p>
<p>Each (stack, buffer, POS) → action pair becomes a training sample.</p>
<p>The original graph tells us what the right action should be at each step — but the classifier never gets the full graph as input.</p>
<p>Instead of making the model predict an entire tree at once (too hard),</p>
<p>We teach it moment-by-moment what the best move is,</p>
<p>Based on the gold dependency tree created by humans.</p>
<h1 id="example">Example<a class="headerlink" href="#example" title="Permanent link">&para;</a></h1>
<p>Suppose sentence:
"She eats apples."</p>
<p>Gold parse says:</p>
<p>"eats" is root</p>
<p>"She" → subject of "eats"</p>
<p>"apples" → object of "eats"</p>
<p>Training samples would look like:</p>
<p>Partial state (stack, buffer, POS)  Best action (label)
Stack: [], Buffer: [She, eats, apples], POS: [...]  shift
Stack: [She], Buffer: [eats, apples], POS: [...]    shift
Stack: [She, eats], Buffer: [apples], POS: [...]    left-arc (subject)
Stack: [eats], Buffer: [apples], POS: [...] shift
Stack: [eats, apples], Buffer: [], POS: [...]   right-arc (object)</p>
<p>We train on (parser state → next action) pairs.
We build the full graph by stringing together many next actions.
The original annotated dependency graph is used only to supervise, not fed in directly.</p>
<hr />
<p>During Inference:
We have a new sentence.</p>
<p>Start:</p>
<p>Stack is empty []</p>
<p>Buffer has all the words of the new sentence [The, cat, eats, fish]</p>
<p>POS tags are already assigned (by a separate POS-tagger)</p>
<p>At each step:</p>
<p>The parser looks at the current stack + buffer (+ POS tags)</p>
<p>Uses the trained classifier to predict the best action: shift, left-arc, or right-arc (and maybe dependency label)</p>
<p>Apply the predicted action:</p>
<p>If classifier says shift: move word from buffer to stack</p>
<p>If left-arc: create an arc and pop the second-to-top word from the stack</p>
<p>If right-arc: create an arc and pop the top word from the stack</p>
<p>Repeat:</p>
<p>Keep feeding the new parser state into the model</p>
<p>Keep taking actions</p>
<p>Until the buffer is empty and only one item remains on the stack (the root)</p>
<p>Result:</p>
<p>You have a <strong>dependency graph</strong> for the whole sentence!</p>
<p>By dependency parsing the arc map we can make tuples from the unstructured sentences <subject, relation, object>, because it walks us through the graph of the sentence.</p>
<p>Put these tuples in the knowledge base to tell us the different ways the entities are related to each other. This makes a structured database.</p>
<p>If we don't have perfect matches we use distributional approaches to match questions to relations. Cosine similarity helps us decide if this is the best tuple: we use cosine similarity between different parts of the sentence and pieces of info we have in the tuple.</p>
<p>Parse a sentence → build a dependency graph (using your shift-reduce parser).</p>
<p>Walk the dependency graph to extract meaningful (subject, relation, object) triples:</p>
<p>Subject = the entity doing the action</p>
<p>Relation = the action or link</p>
<p>Object = the entity receiving the action</p>
<p>→ Example:
Sentence: "The cat eats fish."
Dependency graph shows:</p>
<p>cat (subject) → eats (verb)</p>
<p>eats → fish (object)
Tuple extracted: (cat, eats, fish)</p>
<p>Store the triples in a knowledge base:</p>
<p>Now you have structured, machine-readable data!</p>
<p>Entities are related by known relationships.</p>
<p>Natural language is messy: different ways to say the same thing.</p>
<p>Distributional approaches help:</p>
<p>Use word embeddings (like Word2Vec, GloVe) to represent words or phrases as vectors.</p>
<p>Use cosine similarity between:</p>
<p>Words in the question</p>
<p>Words in the knowledge base tuples</p>
<p>This lets you approximate matches, even if the phrasing isn't exactly the same.</p>
<p>Example:</p>
<p>Question: "What does a feline consume?"</p>
<p>Knowledge base: (cat, eats, fish)</p>
<p>Even though "feline" ≠ "cat" and "consume" ≠ "eats," cosine similarity would reveal they're close!</p>
<hr />
<p>That works for who what where and when questions. But why questions are harder.</p>
<p>Events are descriptions of changes in the state of world (actual or implied). We need to get at the semantics of the events because these are not in the text.</p>
<p>Frames:
Acknowledge that a word's meaning cannot be understood without access to essential knowledge that relates to the world.</p>
<p>A Frame is a system that relates concepts such that understanding one concept requires the understanding of all concepts and their relationships</p>
<p>circular: seller &gt; sell &gt; recipient &gt; possession &gt; seller ...</p>
<p>FrameNet: avenger, punishment, offender, injury, injured-party
Made by humans
Lexical units can bring up this frame: get back at, get even, avenge...</p>
<p>If we can identify the frame and the frame elements, we can make inferences about the relationships between the frame elements that we might not be able to do from just the surface form of the sentence.</p>
<p>Sally wanted to get back at Jane after her cat died.
Why did sally want to do this?
"We need to understand 'get back at'.</p>
<p>VerbNet: Linguist resource of frames centered around verbs.</p>
<p>Links syntactic and semantic patterns.</p>
<p>Can be used for:
Word Sense Disambiguation 
Figurative Language Detection</p>
<p>VerbNet organizes verbs into classes based on their meaning and syntax.</p>
<p>Each verb class defines:</p>
<p>What kinds of participants (roles) it expects (Agent, Patient, Instrument, etc.)</p>
<p>What kinds of syntactic frames are typical (subject-verb-object, subject-verb, etc.)</p>
<p>It also gives semantic roles and predicates that describe the event structure clearly.</p>
<p>Key: VerbNet links natural language to structured events and roles.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.top", "navigation.sections"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>