
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../patterns/stats/">
      
      
        <link rel="next" href="bayes_learning/">
      
      
      <link rel="icon" href="../assets/images/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Overview - AI and ML Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#machine-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI and ML Notes" class="md-header__button md-logo" aria-label="AI and ML Notes" data-md-component="logo">
      
  <img src="../assets/images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI and ML Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Overview
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI and ML Notes" class="md-nav__button md-logo" aria-label="AI and ML Notes" data-md-component="logo">
      
  <img src="../assets/images/logo.png" alt="logo">

    </a>
    AI and ML Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Patterns
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Patterns
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../patterns/glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../patterns/stats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability & Statistics
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Machine Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#computation-learning-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Computation Learning Theory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Computation Learning Theory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pac-learning-probably-approximately-correct-error-of-hypothesis-h" class="md-nav__link">
    <span class="md-ellipsis">
      PAC Learning : Probably Approximately Correct : Error of Hypothesis h
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vc-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      VC Dimensions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#information-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Information Theory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Information Theory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#information-between-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Information Between Variables
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="bayes_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bayesian Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="clustering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clustering
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="decision_trees/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decision Trees
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="feature/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Features
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="instance_based/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Instance Based Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural Nets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="rand_optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Random Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="svm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SVM
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    NLP
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            NLP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp/distributional_semantics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributional Semantics
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Deep Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Deep Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    AI for Robotics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            AI for Robotics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../robotics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rl/game_theory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Game Theory
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#computation-learning-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Computation Learning Theory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Computation Learning Theory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pac-learning-probably-approximately-correct-error-of-hypothesis-h" class="md-nav__link">
    <span class="md-ellipsis">
      PAC Learning : Probably Approximately Correct : Error of Hypothesis h
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vc-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      VC Dimensions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#information-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Information Theory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Information Theory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#information-between-variables" class="md-nav__link">
    <span class="md-ellipsis">
      Information Between Variables
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="machine-learning"><strong>Machine Learning</strong><a class="headerlink" href="#machine-learning" title="Permanent link">&para;</a></h1>
<p><a href="https://www.youtube.com/watch?v=DQWI1kvmwRg"><img alt="Watch on YouTube" src="https://img.youtube.com/vi/DQWI1kvmwRg/3.jpg" /></a></p>
<p>An inductive learner uses examples to find the best hypothesis h* from some class H. H is the set of possible answers to the problem. Think of hypothesis h as candidate answers.</p>
<h2 id="computation-learning-theory"><strong>Computation Learning Theory</strong><a class="headerlink" href="#computation-learning-theory" title="Permanent link">&para;</a></h2>
<p>log base 2, is like keep dividing by 2</p>
<h3 id="pac-learning-probably-approximately-correct-error-of-hypothesis-h"><strong>PAC Learning : Probably Approximately Correct : Error of Hypothesis h</strong><a class="headerlink" href="#pac-learning-probably-approximately-correct-error-of-hypothesis-h" title="Permanent link">&para;</a></h3>
<p>Training Error: Fraction of training examples misclassified by h.<br />
Target concept should have training error of zero.<br />
\(error_d (h_i) &gt; \epsilon\) means h is wrong, aka  \( h_i \neq c_i \)</p>
<p>True Error: Fraction of examples that <em>would be</em> misclassified on sample drawn from D in, essentially, the infinite limit. The probability that a sample drawn from D would be misclassified by some hypothesis h. </p>
<p>\(  error_d(h) = P(c(x) \neq h(x))\) in x~D distribution </p>
<p>So we are not penalized for examples that we never see. And examples that we see rarely, we only get a time bit of contribution to the overall error.</p>
<p>C is PAC-Learnable by <em>L</em> using <em>H</em>, \(iff\) learning <em>L</em> will, with high probability ( at least \(  1-\delta\)), output a hypothesis h \(\in\) <em>H</em> that it is very accurate \( (error_D(h) \leq \epsilon)\); and in time and samples it is bounded by polynomial in \(  1/\epsilon, 1/\delta,\)and n. </p>
<p>If we want perfect error and perfect certainty than the denominators go to infinity as we look at all the data.</p>
<p><strong>Something is PAC-learnable if we can learn a hypothesis with low error and high confidence in polynomial time. Sample complexity tells us how many training examples we need to guarantee this level of performance.</strong> </p>
<ul>
<li>True Hypothesis: \(  c \in  H \) : hypothesis aka function</li>
<li>Concept: <em>c</em> aka label</li>
<li>Concept Class: The class from which the concept that we are trying to learn comes from.   </li>
<li>Hypothesis Space: H : The set of mappings that the learning is going to consider.  </li>
<li>Size of the hypothesis space: |H|: n  </li>
<li>Distribution over inputs: D </li>
<li><strong>Version Space</strong>: VS(S) = { <em>h</em> s.t. h \(\in H \text{consistent wrt} S\) : hypothesis consistent with examples : <strong>the function we learned labels the data correctly</strong>.   </li>
<li>Error Goal: \(   0 \leq \epsilon \leq 1/2\) : We'd like the error in the hypothesis that we produce to be no larger than epsilon.  <em>Approximately</em> in PAC  </li>
<li>Certainty Goal: \(  0 \leq \delta \leq 1/2\) : We might be unlucky and not meet our error goal, \(  \delta\) allows us to set a certainty goal, which means with \(   P(1 - \delta)\), the algorithm has to work. To work, here, means to produce a True Error \( \leq  \epsilon\). <em>Probably</em> in PAC. \(   \delta\) is our confidence paramater in PAC</li>
</ul>
<p>Haussler's Theorem (Realizable Case)</p>
<p>Let H be a finite hypothesis class, and let h \(\in\) H be a hypothesis consistent with a training set of <em>m</em> examples drawn i.i.d. from an unknown distribution <em>D</em>. Suppose the target function <em>f</em> is h \(\in\) H (i.e., the realizable case).</p>
<p>Then for any \(\epsilon &gt; 0\) and \(\delta \in (0, 1)\), if</p>
<p>\(
m \geq \frac{1}{\epsilon} \left( \ln |H| + \ln \frac{1}{\delta} \right),
\)</p>
<p>then with probability at least \(1 - \delta\), every hypothesis \(h \in H\)that is consistent with the training data satisfies</p>
<p>\(
\Pr_{x \sim D} [h(x) \neq f(x)] \leq \epsilon.
\)</p>
<p>And for infinite hypothesis class:</p>
<p>\(
m \geq \frac{1}{\epsilon} \left( (8 \cdot VC |H|) \cdot \log_2 + 4\log_2 \frac{2}{\delta} \right),
\)</p>
<p>As VS|H| gets bigger we need more data.</p>
<p><em>So...</em>   <br />
<strong>H is PAC-Learnable \(iff\) VC dimension is finite.</strong></p>
<h3 id="vc-dimensions"><strong>VC Dimensions</strong><a class="headerlink" href="#vc-dimensions" title="Permanent link">&para;</a></h3>
<p>VC Dimensions help us determine how much data we need to learn effectively even if the hypothesis class is infinite. It expresses how expressive or powerful a model class is in terms of what patterns it can learn: this is a measure of complexity or capacity. </p>
<p>Most of the algorithms we use have an infinite hypothesis space:<br />
- linear separators: there are infinite number of lines to choose from since m x and b are reals<br />
- NN: each weights has an infinite amount of numbers it can be since weights are reals<br />
- decision trees with continuous inputs: infinite number of questions we can ask at decision nodes<br />
- ...</p>
<p>How all of our ML algorithms work is like this: keep track of <em>all</em> hypotheses and keep this <strong>version space</strong>. Once we see enough examples randomly drawn we know we've <strong>epsilon-exhausted</strong> the version space. So any hypothesis that is left is going to be ok.</p>
<p>But we can't keep track of infinite hypotheses.</p>
<p>So we will find a way to keep track of only the hypothesis that can affect the outcome differently. </p>
<p>Example:
X: {1,2,3,4,5,6,7,8,9,10}<br />
H: {h(x) = x \(  \leq \theta \)}</p>
<p>|H| = \(  \infty \)</p>
<p>But only \(  \theta \) above 10 is important</p>
<p>VC Dimension it the maximum number of points that can be shattered by the hypotheses in that space.</p>
<p>Shatter: For every possible labeling (0/1 classification) of the points, there exists a hypothesis (a classifier from your class) that perfectly separates the points according to that labeling.</p>
<p>VC dimension depends on the hypothesis class, not strictly the number of input features. Example: Both a circle and a sphere have 2 VC dimensions</p>
<p>High VC dimension mean the model can shatter more configurations, increasing the risk of over fit, likewise lower VC dimensions may to under fitting and poor accuracy if they are too low.</p>
<h2 id="information-theory"><strong>Information Theory</strong><a class="headerlink" href="#information-theory" title="Permanent link">&para;</a></h2>
<p>In ML we want to know:</p>
<ol>
<li>How each input relates to <em>y</em></li>
<li>Which input splits our output best, giving us the most <em>information</em> about y</li>
</ol>
<p>In general every input vector and output vector can be considered a <em>probability density function</em>.</p>
<p><strong>Information Theory</strong> is a mathematical framework that allows us to compare these density functions.</p>
<p>Are input vectors are similar:  <strong>mutual information</strong></p>
<p>Does this feature have any information: <strong>entropy</strong></p>
<p>If output is predictable we don't need to communicate. Uncertain, meaningful information is harder to communicate and require more resources.</p>
<p>more predictable \(\approx\) less uncertainty \(\approx\) less information \(\approx\) less entropy</p>
<p>Example: Which message has more information?<br />
Given:<br />
- Language L={A,B,C,D}<br />
- Each word is represented by 2 bits, and occur with a specified probability.</p>
<p>First lets assume all words occur equally:</p>
<p>A: 00   25%<br />
B: 01   25%<br />
C: 10   25%<br />
D: 11   25%  </p>
<p>We have a sequence spelling BAD: 01 00 11</p>
<p>2 bit (1 or 0) symbol representation means we have to ask two yes or no questions per symbol.</p>
<p>Think of it as a tree. When we have a new bit coming in it can be 0 or 1 equally. So we ask two question, each "Is it 1?"</p>
<p>Is it one? Answer:   0 1<br />
Is it one? Answer:0 1   0 1<br />
Conclusion:       A B   C D  </p>
<p>Second message:</p>
<p>A: 50%<br />
B: 12.5%<br />
C: 12.5%<br />
D: 25%  </p>
<p>Since A occurs most frequently we can actually use less than two bits to represent each symbol. How should we represent it?</p>
<p>For the tree our first question is "Is it A?"</p>
<p>Is it A?:           0 1 <br />
Semi-conclusion:    A<br />
Is it D?:             0 1<br />
Semi-conclusion:      D<br />
Is it 1?                0 1 <br />
                        B C  </p>
<p>So<br />
A: 0<br />
D: 10<br />
B: 110<br />
C: 111   </p>
<p>Since A occurs most frequently and we only have to ask one question to determine if the symbol is A, we can ask less questions overall. We use the expected value to find out how much exactly.</p>
<p>\(\sum P(\text{symbol}) \times \text{size of symbol}\): (<strong>Entropy</strong>)
= 1P(A) + 2P(D) + 3P(B) + 3P(C)<br />
= 0.5 + 0.5 + 0.375 + 0.375<br />
= 1.75 bits per symbol  </p>
<p>= 1.75 bits &lt; 2 bits </p>
<p>The second language has more information and less randomness.</p>
<p>Note: This technique is called <em>variable length encoding</em> and explains why in morse code some symbols are smaller than others.</p>
<p><strong>Entropy</strong></p>
<p>Entropy captures the in amount of information contained in the variable by quantifying the uncertainty or unpredictability of the variable. </p>
<p>higher entropy \(\approx\) more uncertainty \(\approx\) more information </p>
<p>As shown above:<br />
\(\sum P(\text{symbol}) \times \text{size of symbol}\)</p>
<p>But we need to denote the size of each symbol more properly:</p>
<p>\(\sum P(\text{symbol}) \times \frac{1}{P(\text{size of symbol})}\)</p>
<p>\(H(L) = - \sum P(s) \cdot \log_2 P(s)\)</p>
<h3 id="information-between-variables"><strong>Information Between Variables</strong><a class="headerlink" href="#information-between-variables" title="Permanent link">&para;</a></h3>
<p>Having information about multiple variables can change their probability.</p>
<p>If I hear thunder, it might change my prediction about rain and vice versa.</p>
<p><strong>Joint Entropy</strong>
The amount of uncertainty contained in two variables together:</p>
<p>\(H(x,y) = - \sum P(x,y) \cdot \log P(x,y)\)</p>
<p><strong>Joint Entropy</strong>
\(H(y|x) = - \sum P(x,y) \cdot \log P(y|x)\)</p>
<p><strong>Mutual information</strong> measures the amount of shared information between two variables, by quantifying the reduction in uncertainty of one variable given knowledge of the other — i.e., statistical dependence.</p>
<p>I(X;Y) = H(Y) - H(Y|X)</p>
<p>It is symmetric: </p>
<p>I(Y;X) = I(X;Y) = H(Y)−H(Y∣X) = H(X)−H(X∣Y)</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.top", "navigation.sections"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>